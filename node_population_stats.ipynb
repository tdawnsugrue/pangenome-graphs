{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d157d830",
   "metadata": {},
   "source": [
    "# Getting Chr5 novel node statistics\n",
    "\n",
    "This is more or less following the hpgp-basics doc, but through python rather than R.\n",
    "\n",
    "First, we need to import stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "35bcc145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4921090.txt', '4905845.txt', '4950687.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "node_dir = \"nonref_files/chr5-1k-10-50/\"\n",
    "nodes = os.listdir(node_dir)\n",
    "\n",
    "sample_data = pd.read_csv(\"nonref_files/20130606_g1k_3202_samples_ped_population.txt\", \n",
    "                         delimiter=\" \")\n",
    "sample_data[\"SampleID\"] = sample_data[\"SampleID\"].astype(str)\n",
    "\n",
    "sample_data\n",
    "print(nodes[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd8699",
   "metadata": {},
   "source": [
    "Now we need to get all the path information for each node, and convert it into a dataframe so we can do something useful with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "883de34e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SampleID  count Population\n",
      "0   HG01071      1        PUR\n",
      "1   HG01109      1        PUR\n",
      "2   HG01175      1        PUR\n",
      "3   HG01891      1        ACB\n",
      "4   HG02080      1        KHV\n",
      "5   HG02145      1        ACB\n",
      "6   HG02148      1        PEL\n",
      "7   HG02622      2        GWD\n",
      "8   HG02630      1        GWD\n",
      "9   HG02723      1        GWD\n",
      "10  HG02886      2        GWD\n",
      "11  HG03098      1        MSL\n",
      "12  HG03486      1        MSL\n",
      "13  HG03492      1        PJL\n",
      "14  HG03579      1        MSL\n"
     ]
    }
   ],
   "source": [
    "pop_counts = {}\n",
    "node_data = \"\"\n",
    "nid = \"\"\n",
    "\n",
    "for node in nodes[:1]: # only working on the first node for now\n",
    "    nid = node[:node.find(\".\")]\n",
    "    paths = open(node_dir + node).read().split('\\n')[:-2] # 2 trailing newlines\n",
    "    \n",
    "    counts = []\n",
    "    # converting to a set makes sure homozygotes are only counted once\n",
    "    for path in sorted(list(set(paths))):\n",
    "        counts.append((path, paths.count(path)))\n",
    "    \n",
    "    # grab population counts\n",
    "    test = pd.DataFrame(counts, columns=[\"SampleID\", \"count\"])\n",
    "    test[\"SampleID\"] = test[\"SampleID\"].astype(str)\n",
    "    test = test.merge(sample_data[[\"SampleID\", \"Population\"]], on=\"SampleID\")\n",
    "    pop_counts[nid] = test[\"Population\"].value_counts()\n",
    "    \n",
    "    # we can work on the whole thing later, but let's just grab one node for now.\n",
    "    node_data = test\n",
    "    print(node_data)\n",
    "\n",
    "# some completely unnecessary data transformation - may be interesting later...    \n",
    "test = pd.DataFrame.from_dict(pop_counts).reset_index()\n",
    "test = pd.pivot_table(test, columns=\"Population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550705e6",
   "metadata": {},
   "source": [
    "We can now use `node_data` to get information about the populations in our node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "184cc8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for 4921090:\n",
      "Population\n",
      "GWD    4\n",
      "PUR    3\n",
      "MSL    3\n",
      "ACB    2\n",
      "KHV    1\n",
      "PEL    1\n",
      "PJL    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Counts for {nid}:\")\n",
    "print(node_data[\"Population\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63855f5c",
   "metadata": {},
   "source": [
    "We can see that most of the paths represented are part of the GWD, PUR, and MSL populations.\n",
    "\n",
    "We can then grab the path prefixes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1d986ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    Gambian in Western Division, The Gambia\n",
      "Name: Population Description, dtype: object\n",
      "   SampleID  count Population\n",
      "7   HG02622      2        GWD\n",
      "8   HG02630      1        GWD\n",
      "9   HG02723      1        GWD\n",
      "10  HG02886      2        GWD\n"
     ]
    }
   ],
   "source": [
    "populations = pd.read_csv(\"data/20131219.populations.tsv\", delimiter=\"\\t\")\n",
    "print(populations[populations[\"Population Code\"] == \"GWD\"][\"Population Description\"])\n",
    "\n",
    "\n",
    "\n",
    "print(node_data[node_data[\"Population\"]==\"GWD\"])\n",
    "\n",
    "path_prefixes = node_data[node_data[\"Population\"]==\"GWD\"][\"SampleID\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be5ad9",
   "metadata": {},
   "source": [
    "Due to the way we extracted the path names, we have to rerun odgi.\n",
    "\n",
    "Because I am silly, we have to extract, then get the paths, *then* extract again. Also note that this also grabs heterozygotes (we can deal with that later).\n",
    "\n",
    "We can also use the interface (or just odgi viz) to grab the visualisation for this node - or visualise the wider region (probably better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5fd79cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_og = f\"nonref_files/chr5-1k-10-50/node_{nid}.og\"\n",
    "\n",
    "subprocess.run([\"./bin/odgi\", \"extract\", \"-i\", \"chr5.full.og\", \"-n\", nid,\n",
    "                \"-o\", node_og, \"-t\", \"4\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59affae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HG02622#1#JAHAOO010000060.1#0:27547620-27548750', 'HG02622#2#JAHAON010000051.1#0:21697577-21698707', 'HG02630#2#JAHAOP010000044.1#0:21714757-21715887', 'HG02723#2#JAHEOT010000033.1#0:26930289-26931419', 'HG02886#1#JAHAOU010000047.1#0:21754255-21755385', 'HG02886#2#JAHAOT010000044.1#0:21627707-21628837']\n"
     ]
    }
   ],
   "source": [
    "paths = subprocess.run([\"./bin/odgi\", \"paths\", \"-i\", node_og,\n",
    "                       \"-L\"], capture_output=True).stdout.decode().split()\n",
    "        \n",
    "paths = [p for p in paths if p[:p.find(\"#\")] in path_prefixes]\n",
    "print(paths)\n",
    "\n",
    "f = open(\"_paths.txt\", \"w\") #remove later\n",
    "\n",
    "for p in paths:\n",
    "    f.write(p + \"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81a79b",
   "metadata": {},
   "source": [
    "In theory, we could then extract specific paths - no need to do that here; paths in the graph are all exactly the same within that node. (See visualisation in the `img` folder of the repo, alternatively you can run `odgi viz` to get sequence info)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
